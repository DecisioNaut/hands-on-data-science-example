{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\\\"https://colab.research.google.com/github/QuantificAid/hands-on-data-science-example/blob/master/hands-on-data-science-example.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science zum Mitmachen: Wetter, Radfahrer und mehr..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie wir in der Bastelstrecke von [diy-iot2ds](https://github.com/birds-on-mars/diy-iot2ds) lernen können, ist es gar nicht sooo schwer und aufwendig, Wetterdaten automatisch zu erfassen. Allerdings ist die Analyse der isolierten Daten etwas ... gähn. Um spannendere Dinge zu tun und zu erkennen, muss man schon ein paar verschiedene Daten zusammenbringen.\n",
    "\n",
    "Und auch das ist machbar! **Einen kleinen Teil des Ganzen muss/darf der geneigte Leser dabei selber machen.**\n",
    "Google bietet eine kostenlose Umgebung dafür an. Falls noch nicht geschehen, jetzt **bitte einfach oben den Button \"open in colab\" anklicken** (und nach Studie der Bedingungen von Google diese ggf. akzeptieren, damit die Kiste läuft). \n",
    "\n",
    "Um dies zu veranschaulichen haben wir uns von Jake van der Plas, einem Astrophysiker, Data Science-Meister und Python-Guru inspirieren lassen. Jake hält nicht nur viele Talks zum Thema und hat hervorragende Bücher wie das [Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) geschrieben, das es übrigens komplett open-source und interaktiv durch- und zu bearbeiten gibt. Er schreibt auch seit längerem einen Blog, in dem er auch immer wieder Methoden anschaulich beschreibt.  \n",
    "\n",
    "In 2014 hat er dort die Frage gestellt, ob es einen Aufschwung in der Nutzung von Fahrrädern in Seattle gibt. Hier der [Link zum Blog von dunnemals](https://jakevdp.github.io/blog/2014/06/10/is-seattle-really-seeing-an-uptick-in-cycling/).  \n",
    "\n",
    "**Hier werden öffentlich zugängliche und recht volatile Daten zum (automatisch erfassten) Fahrrad-Verkehr über die Fremont-Brücke in Seatlle mit Wetter- und auch berechneten Daten in Verbindung gebracht, um zu verifizieren, ob es tatsächlich eine Veränderung der Fahrrad-Fahrten im Laufe der Zeit gibt bzw. welchen Einfluss andere Umgebungsdaten haben.** \n",
    "\n",
    "Die Antwort von Jake van der Plas in seinem Blog damals war: ja, es gibt einen Zuwachs an Fahrradverkehr.\n",
    "Jetzt sind wir ein paar Jahre weiter und wir fragen uns daher: ist das immer noch der Fall?  \n",
    "\n",
    "Let's see..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwendete Datenquellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auf den Fahrradwegen der Fremont-Brücke in Seattle werden mit magnetischen Induktionsschleifen automatisch Fahrräder gezählt. Da [Open-Data](https://de.wikipedia.org/wiki/Open_Data) in den USA auch bei öffentlichen Institutionen recht verbreitet ist, sind diese Daten frei zugänglich. Sie werden [auf dem Open-Data-Portal der Stadt Seattle bereitgestellt](https://data.seattle.gov/Transportation/Fremont-Bridge-Hourly-Bicycle-Counts-by-Month-Octo/65db-xm6k). Die hier im Repository hinterlegten Daten sind vom 04. Juni 2019 und reichen zurück bis 2012.  \n",
    "\n",
    "So sieht übrigens die Fremont-Brücke in Seattle aus:\n",
    "\n",
    "![Fremont-Brücke in Seatlle](https://upload.wikimedia.org/wikipedia/commons/5/50/Seattle_%E2%80%94_Fremont_Bridge_%E2%80%94_%282016-06-12%29%2C_01.jpg)  \n",
    "\n",
    "Auch Wetterdaten aus den USA sind frei zugänglich über das [National Center of Environmental Information](://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND), wo u.a. die Wetterstation des SeaTac Airport in Seattle ausgewählt werden kann (ID der Wetterstation \"USW00024233\"). Hier haben wir uns die letzten verfügbaren Daten vom 25. Juni 2019 (auch zurück bis 2012) besorgt.\n",
    "\n",
    "Die [Daten liegen bereits in diesem Repository](https://github.com/QuantificAid/hands-on-data-science-example/blob/master/Daten/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfad_zu_Daten = 'https://github.com/QuantificAid/hands-on-data-science-example/blob/master/Daten/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorgehen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier werden wir die üblichen Schritte einer Data Science-Analyse durchlaufen:\n",
    "- **Laden und erstes Explorieren der Daten** (*Gathering*) verbunden mit einer ersten ganz kurzen ersten Exploration, wie die Daten in der Rohversion aussehen.\n",
    "- **Strukturieren der Daten** (*Preprocessing*) um die Daten in eine gesamthaft weiterverarbeitbare Form zu bringen.\n",
    "- **Bereinigung und weitere Exploration der Daten** *(Cleansing, Exploration)*, um die Daten in die finale Form für die Modellbildung zu bringen. Glücklicherweise sind die Daten recht \"sauber\", was den ansonsten oft sehr mühseligen Teil der Bereinigung sehr kurz macht. Wir werden die Daten aber recht ausgiebig visualisieren.\n",
    "- Last, but not least **Modellierung der Daten** *(Modelling)*. Hier benutzen wir werden wir eine \"einfache\" multi-lineare Regression anwenden, um zu prüfen, welcher Einflussfaktor wie (linear) wirkt und welcher Trend sich am Ende für den zeitlichen Verlauf der Fahrrad-Nutzung ergibt. Wie lineare Regression funktioniert wird im entsprechenden Teil erläutert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verwendete Programmbibliotheken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Analyse der Daten nehmen wir in der Programmiersprache Python vor, die für sehr vieles geeignet ist, aber auch sehr beliebt für Data Science, Machine Learning und AI ist.\n",
    "\n",
    "Sie ist nicht nur deshalb in diesen Gebieten so beliebt, weil sie relativ leicht zu lernen und sehr vielseitig ist, sondern auch und insbesondere, weil es viele schlaue Geister in Python sehr coole Programm-Bibliotheken geschrieben haben, die open source bereitstehen, deren enthaltene Objekte, Methoden und Funktionen sofort verwendet werden können und die einem viel Arbeit abnehmen.\n",
    "\n",
    "Wir laden uns die folgenden Bibliotheken:\n",
    "- [pandas](https://pandas.pydata.org/) zur effizienten Bearbeitung von Datentabellen\n",
    "- [NumPy](https://www.numpy.org/) zur schnellen numerischen Bearbeitung von Tabellendaten und Matrizen (wird im Hintergrund auch von pandas verwendet)\n",
    "- [altair](https://altair-viz.github.io/) zur grafischen und interaktiven Darstellung von Daten und\n",
    "- [scikit-learn oder auch sklearn](https://scikit-learn.org/stable/), einer elegant programmierten Bibliothek mit vielen Funktionen zum maschinellen Lernen (u.a. der linearen Regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importieren von Programm-Bibliotheken\n",
    "\n",
    "# Programm-Bibliothek zur effizienten Bearbeitung von Datentabellen\n",
    "import pandas as pd\n",
    "\n",
    "# Programm-Bibliothek zur schnellen numerischen \n",
    "# Bearbeitung von Tabellendaten und Matrizen.\n",
    "import numpy as np\n",
    "\n",
    "# Programm-Bibliothek zu grafischen und interaktiven \n",
    "# Darstellung von Daten\n",
    "import altair as alt\n",
    "alt.renderers.enable('notebook')\n",
    "\n",
    "# Programm-Bibliothek u.a. Lineare Regression\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laden und erstes Explorieren der Daten *(Gathering, First Exploration)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden und erstes Explorieren der Verkehrsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d443933663e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# im Ordner 'Daten'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m Verkehrsdaten = pd.read_csv(\n\u001b[0;32m----> 5\u001b[0;31m     Pfad_zu_Daten + 'Fremont_Bridge_Hourly_Bicycle_Counts_by_Month_October_2012_to_present.csv')\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_infer_compression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     filepath_or_buffer, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 413\u001b[0;31m         filepath_or_buffer, encoding, compression)\n\u001b[0m\u001b[1;32m    414\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'gzip'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 641\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/diy-iot2ds/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Laden der 'Verkehrsdaten' \n",
    "# aus Datei'Fremont_Bridge_Hourly_Bicycle_Counts_by_Month_October_2012_to_present.csv' \n",
    "# im Ordner 'Daten'\n",
    "Verkehrsdaten = pd.read_csv(\n",
    "    Pfad_zu_Daten + 'Fremont_Bridge_Hourly_Bicycle_Counts_by_Month_October_2012_to_present.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen der obersten Reihe der 'Verkehrsdaten'\n",
    "Verkehrsdaten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen der untersten Reihen der 'Verkehrsdaten'\n",
    "Verkehrsdaten.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Abstrakte Information über die 'Verkehrsdaten'\n",
    "Verkehrsdaten.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grundlegende Statistik der 'Verkehrsdaten'\n",
    "Verkehrsdaten.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Do-It-Yourself: Laden und erstes Explorieren der Wetterdaten*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen der 'Wetterdaten' \n",
    "# aus Datei '178440.csv' \n",
    "# im Ordner 'Daten' \n",
    "Wetterdaten = pd.read_csv('Daten/1786440.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen der obersten Reihe der 'Wetterdaten'\n",
    "Wetterdaten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen der untersten Reihe der 'Wetterdaten'\n",
    "Wetterdaten.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Abstrakte Information über die 'Wetterdaten'\n",
    "Wetterdaten.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grundlegende Statistik der 'Wetterdaten'\n",
    "Wetterdaten.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strukturieren der Daten *(Preprocessing)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Anlegen einer neuen Datenstruktur 'Daten'\n",
    "Daten = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formattieren und Aggregieren und Hinzufügen der Verkehrsdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst formatieren wir die Spalte 'Date' von 'verkehrsdaten' in ein Format um, dass von 'pandas' als Zeiten interpretiert werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Konvertieren der Spalte 'Date' in 'Verkehrsdaten'\n",
    "# in ein \"echtes\" Datumsformat\n",
    "Verkehrsdaten['Date'] = pd.to_datetime(Verkehrsdaten['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann setzen wir den Index der Tabelle 'verkehrsdaten' auf 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ersetzen der Index-Spalte mit der Spalte 'Date' aus 'Verkehrsdaten'\n",
    "Verkehrsdaten = Verkehrsdaten.set_index('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Vergleichbarkeit zu den Wetterdaten zu erreichen, aggregieren wir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Aggregieren und Ersetzen der stündlichen 'Verkehrsdaten' \n",
    "# durch tägliche 'Verkehrsdaten'\n",
    "Verkehrsdaten = Verkehrsdaten.resample('d').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielreihen der 'Verkehrsdaten'\n",
    "Verkehrsdaten.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Abstrakte Information über 'Verkehrsdaten'\n",
    "Verkehrsdaten.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grundlegende Statistik der 'Verkehrsdaten'\n",
    "Verkehrsdaten.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Übertragen der Summe der Spalten aus den 'Verkehrsdaten'\n",
    "# in eine (neue) Spalte 'Fahrten' der 'Daten'\n",
    "Daten['Fahrten'] = Verkehrsdaten['Fremont Bridge East Sidewalk'] + Verkehrsdaten['Fremont Bridge West Sidewalk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Benennung des Index der 'Daten' mit 'Datum'\n",
    "Daten.index = pd.DatetimeIndex(data=Verkehrsdaten.index, name='Datum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielreihen aus den 'Daten'\n",
    "Daten.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ermitteln und Hinzufügen berechneter Daten (Tageslänge und Wochentag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Anlegen einer neuen Datenstruktur 'Berechnete_Daten'\n",
    "# mit Übernahme der Index-Struktur von 'Daten'\n",
    "Berechnete_Daten = pd.DataFrame(index=Daten.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Neue Spalte 'Tag' in 'Berechnete_Daten'\n",
    "# aus den Zahlenwerten des 'index' (der das Datum enthalt)\n",
    "Berechnete_Daten['Tag'] = pd.to_numeric(Berechnete_Daten.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielsreihen aus 'Berechnete Daten'\n",
    "Berechnete_Daten['Tag'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Umwandeln der Spalte 'Tag' in ganzzahlige Werte\n",
    "# die einzelnen Tagen entsprechen\n",
    "Tageslaenge_in_Nanosekunden = 24*60*60*1_000_000_000\n",
    "Berechnete_Daten['Tag'] = (Berechnete_Daten['Tag'] - Berechnete_Daten['Tag'].min()) \\\n",
    "                        / Tageslaenge_in_Nanosekunden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen der ersten Reihen von 'Berechnete Daten'\n",
    "Berechnete_Daten.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Formel zur Berechnung der Tageslänge in Abhängigkeit des\n",
    "# Datums und des Laengengrades \n",
    "# (voreingestellt ist der Längengrad von Seattle)\n",
    "\n",
    "def Berechne_Tageslaenge(Datum, Laengengrad=47.61):\n",
    "    \n",
    "    # Neigung der Erdachse in Grad\n",
    "    Neigung_erdachse = 23.44\n",
    "    \n",
    "    # Wintersonnenwende\n",
    "    Wintersonnenwende = pd.datetime(2000, 12, 21)\n",
    "    \n",
    "    # Tage seit Wintersonnenwende (WSW)\n",
    "    Zeit_seit_WSW = Datum - Wintersonnenwende\n",
    "    Tage_seit_WSW = Zeit_seit_WSW.total_seconds() / (24. * 60. * 60.)\n",
    "    Tage_seit_WSW = Tage_seit_WSW % 365.25\n",
    "    \n",
    "    m = 1. - \\\n",
    "        np.tan(np.radians(Laengengrad)) * \\\n",
    "        np.tan(\n",
    "            np.radians(Neigung_erdachse) * \n",
    "            np.cos(Tage_seit_WSW * np.pi / 182.625) \n",
    "    )\n",
    "    \n",
    "    m = max(0, min(m, 2))\n",
    "    \n",
    "    Tageslaenge = 24. * np.degrees(np.arccos(1 - m)) / 180.\n",
    "    \n",
    "    return Tageslaenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Aufbau einer Liste von Tageslaengen und \n",
    "# Übernahme in eine neue Spalte 'Tageslaenge'\n",
    "# in 'Berechnete_Daten'\n",
    "Tageslaengen = list(map(Berechne_Tageslaenge, Berechnete_Daten.index))\n",
    "Berechnete_Daten['Tageslaenge'] = Tageslaengen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielreihen aus 'Berechnete Daten'\n",
    "Berechnete_Daten.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Berechnung, ob ein Tag ein Werktag \n",
    "# ist (1) oder nicht (0) und\n",
    "# Übernahme in eine neue Spalte 'ist_Werktag' von 'Berechnete_Daten'\n",
    "Berechnete_Daten['ist_Werktag'] = 1 - Berechnete_Daten.index.dayofweek // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielreihen aus 'Berechnete Daten'\n",
    "Berechnete_Daten.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Übernahme von 'Tageslaenge' und 'ist_Werktag'\n",
    "# aus 'Berechnete_Daten' in die 'Daten'\n",
    "Daten[['Tag', 'Tageslaenge', 'ist_Werktag']] = Berechnete_Daten[['Tag', 'Tageslaenge', 'ist_Werktag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielreihen aus 'Daten'\n",
    "Daten.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Do-It-Yourself: Formatieren und Hinzufügen ausgewählter Wetterdaten*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Konvertieren der Spalte 'DATE' in 'Wetterdaten'\n",
    "# in ein \"echtes\" Datumsformat\n",
    "# (vgl. 'Formattieren und Aggregieren und Hinzufügen der Verkehrsdaten')\n",
    "Wetterdaten['DATE'] = pd.to_datetime(Wetterdaten['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ersetzen der Index-Spalte mit der Spalte 'DATE' aus 'Wetterdaten'\n",
    "# (vgl. 'Formattieren und Aggregieren und Hinzufügen der Verkehrsdaten')\n",
    "Wetterdaten = Wetterdaten.set_index('DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Abstrakte Information über 'Wetterdaten'\n",
    "# (vgl. 'Formattieren und Aggregieren und Hinzufügen der Verkehrsdaten')\n",
    "Wetterdaten.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grundlegende Statistik der 'Wetterdaten'\n",
    "# (vgl. 'Formattieren und Aggregieren und Hinzufügen der Verkehrsdaten')\n",
    "Wetterdaten.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Übernahme der Spalten 'TAVG' (average temperature = durchschnittliche Temperatur)\n",
    "# und 'PRCP' (precipitation = Niederschlag) in \n",
    "# neue Spalten von 'Daten' 'Temperatur' und 'Niederschlag'\n",
    "# (vgl. 'Formattieren und Aggregieren und Hinzufügen der Verkehrsdaten')\n",
    "Daten['Temperatur'] = Wetterdaten['TAVG']\n",
    "Daten['Niederschlag'] = Wetterdaten['PRCP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielreihen aus 'Daten'\n",
    "# (vgl. 'Formattieren und Aggregieren und Hinzufügen der Verkehrsdaten')\n",
    "Daten.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bereinigung und weitere Exploration der Daten *(Cleansing, Exploration)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Kopieren von 'Daten' in eine\n",
    "# neue Datentabelle 'DatenQuelle'\n",
    "# um die Daten vor weiterer Veränderung zu schützen\n",
    "DatenQuelle = Daten.copy()\n",
    "DatenQuelle.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Neue Spalte 'Datum' aus dem \n",
    "# Index von DatenQuelle (und\n",
    "# Erzeugen eines neuen, generischen Indexes)\n",
    "DatenQuelle.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lesen von Beispielreihen von 'DatenQuelle'\n",
    "DatenQuelle.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reorganisation der Spaltenreihenfolge\n",
    "DatenQuelle = DatenQuelle[['Datum', 'Tag', 'Fahrten', 'Tageslaenge', 'ist_Werktag', 'Temperatur', 'Niederschlag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grundlegende Statistik von 'DatenQuelle'\n",
    "DatenQuelle.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Löschen aller Reihen die \n",
    "# keine Werte in einer oder mehreren Spalten enthalten\n",
    "DatenQuelle.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Grundlegende Statistik von 'DatenQuelle'\n",
    "DatenQuelle.describe(include='all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Funktion zur Erzeugung\n",
    "# einer Grafik für eine Variable\n",
    "# im zeitlichen Verlauf\n",
    "def Grafik_Verlauf(Abhaengige_Variable='Fahrten', \n",
    "                   DatenQuelle=DatenQuelle, \n",
    "                   # Variablen für die optionale \n",
    "                   # weitere Variation der Grafiken\n",
    "                   # (wird später benutzt)\n",
    "                   Glaettungsfenster=None, \n",
    "                   Auswahlfilter=None):\n",
    "    \n",
    "    if Glaettungsfenster:\n",
    "        \n",
    "        Grafik_Verlauf = alt.Chart(\n",
    "            data=DatenQuelle,\n",
    "            width=600, height=300\n",
    "        ).mark_line(\n",
    "            color='orange', size=2\n",
    "        ).transform_window(\n",
    "            Gelaettete_Variable='mean('+ Abhaengige_Variable + ')',\n",
    "            frame=[0, Glaettungsfenster]\n",
    "        ).encode(\n",
    "            x=alt.X('Datum:T',\n",
    "                    axis=alt.Axis(title=None)),\n",
    "            y=alt.Y('Gelaettete_Variable:Q',\n",
    "                    axis=alt.Axis(title=None)\n",
    "                   )\n",
    "        ).properties(\n",
    "            title='Zeitlicher Verlauf von ' + Abhaengige_Variable + \\\n",
    "            ' (inkl. ' + str(Glaettungsfenster) + '-Tage-Glaettung)'\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        Grafik_Verlauf = alt.Chart(\n",
    "            data=DatenQuelle,\n",
    "            width=600, height=300\n",
    "        ).mark_point(\n",
    "            size=2\n",
    "        ).encode(\n",
    "            x=alt.X('Datum',\n",
    "                    axis=alt.Axis(title=None)),\n",
    "            y=alt.Y(Abhaengige_Variable,\n",
    "                    axis=alt.Axis(title=None)),\n",
    "            tooltip=list(DatenQuelle.columns)\n",
    "        ).properties(\n",
    "            title='Zeitlicher Verlauf von ' + Abhaengige_Variable\n",
    "        )\n",
    "        \n",
    "        if Auswahlfilter:\n",
    "            \n",
    "            Grafik_Verlauf = Grafik_Verlauf.encode(\n",
    "                color=alt.condition(Auswahlfilter,\n",
    "                                    alt.ColorValue('#1f77b4'), \n",
    "                                    alt.ColorValue('lightgrey'))\n",
    "            ).add_selection(Auswahlfilter)\n",
    "            \n",
    "        Trendvariable = 'Trend_' + Abhaengige_Variable + '_iAv_Tag'\n",
    "        \n",
    "        if Trendvariable in DatenQuelle.columns:\n",
    "            \n",
    "            Grafik_Trend = alt.Chart(\n",
    "                data=DatenQuelle\n",
    "            ).mark_line(\n",
    "                color='red', size=2\n",
    "            ).encode(\n",
    "                x=alt.X('Datum'),\n",
    "                y=alt.X(Trendvariable)\n",
    "            )\n",
    "            \n",
    "            Grafik_Verlauf = Grafik_Verlauf + Grafik_Trend\n",
    "        \n",
    "    return Grafik_Verlauf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grafik_Verlauf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grafik_Verlauf(Glaettungsfenster=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grafik_Verlauf(Glaettungsfenster=7) + Grafik_Verlauf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Grafik_Streuung(Unabhaengige_Variable, \n",
    "                    Abhaengige_Variable='Fahrten',\n",
    "                    DatenQuelle=DatenQuelle,\n",
    "                    Auswahlfilter=None):\n",
    "    \n",
    "    Grafik_Streuung = alt.Chart(\n",
    "        data=DatenQuelle,\n",
    "        width=263, height=263\n",
    "    ).mark_point(\n",
    "        size=1\n",
    "    ).encode(\n",
    "        x=alt.X(Unabhaengige_Variable,\n",
    "                scale=alt.Scale(zero=False)),\n",
    "        y=alt.Y(Abhaengige_Variable,\n",
    "                scale=alt.Scale(zero=False)),\n",
    "        tooltip=list(DatenQuelle.columns)\n",
    "    )\n",
    "    \n",
    "    if Auswahlfilter:\n",
    "        \n",
    "        Grafik_Streuung = Grafik_Streuung.encode(\n",
    "            color=alt.condition(Auswahlfilter,\n",
    "                                alt.ColorValue('#1f77b4'), alt.ColorValue('lightgrey'))\n",
    "        ).add_selection(Auswahlfilter)\n",
    "        \n",
    "    Trendvariable = 'Trend_' + Abhaengige_Variable + '_iAv_' + Unabhaengige_Variable\n",
    "    \n",
    "    if Trendvariable in DatenQuelle.columns:\n",
    "        \n",
    "        Grafik_Trend = alt.Chart(\n",
    "            data=DatenQuelle\n",
    "        ).mark_line(\n",
    "            color='red', size=2\n",
    "        ).encode(\n",
    "            x=alt.X(Unabhaengige_Variable),\n",
    "            y=alt.Y(Trendvariable,\n",
    "                    axis=alt.Axis(title=Abhaengige_Variable + ' (mit Trendlinie)'))\n",
    "        )\n",
    "        \n",
    "        Grafik_Streuung = Grafik_Streuung + Grafik_Trend\n",
    "    \n",
    "    return Grafik_Streuung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grafik_Streuung('Tageslaenge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Grafik_Uebersicht(Abhaengige_Variable='Fahrten',\n",
    "                      DatenQuelle=DatenQuelle):\n",
    "    \n",
    "    Auswahlfilter = alt.selection(type='interval', resolve='global')\n",
    "    \n",
    "    Oben = Grafik_Verlauf(Abhaengige_Variable=Abhaengige_Variable, \n",
    "                          DatenQuelle=DatenQuelle, \n",
    "                          Glaettungsfenster=7) \\\n",
    "         + Grafik_Verlauf(Abhaengige_Variable=Abhaengige_Variable,\n",
    "                          DatenQuelle=DatenQuelle,\n",
    "                          Auswahlfilter=Auswahlfilter)\n",
    "    \n",
    "    Links = Grafik_Streuung('Tageslaenge',\n",
    "                            Abhaengige_Variable=Abhaengige_Variable, \n",
    "                            DatenQuelle=DatenQuelle,                            \n",
    "                            Auswahlfilter=Auswahlfilter) \\\n",
    "          & Grafik_Streuung('ist_Werktag',\n",
    "                            Abhaengige_Variable=Abhaengige_Variable, \n",
    "                            DatenQuelle=DatenQuelle,\n",
    "                            Auswahlfilter=Auswahlfilter)\n",
    "    \n",
    "    Rechts = Grafik_Streuung('Temperatur',\n",
    "                            Abhaengige_Variable=Abhaengige_Variable, \n",
    "                            DatenQuelle=DatenQuelle,\n",
    "                            Auswahlfilter=Auswahlfilter) & \\\n",
    "             Grafik_Streuung('Niederschlag',\n",
    "                            Abhaengige_Variable=Abhaengige_Variable, \n",
    "                            DatenQuelle=DatenQuelle,\n",
    "                            Auswahlfilter=Auswahlfilter)\n",
    "    \n",
    "    Grafik_Uebersicht = Oben & (Links | Rechts)\n",
    "    \n",
    "    return Grafik_Uebersicht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grafik_Uebersicht()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellierung der Daten *(Modelling)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineare Regression - eine kurze Einführung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=nk2CQITm_eo\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/nk2CQITm_eo/0.jpg\" \n",
    "alt=\"IMAGE ALT TEXT HERE\" width=\"600\" height=\"400\" border=\"0\" /></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def LR_Modell_und_Daten(Liste_Unabhaengige_Regressionsvariablen,\n",
    "                        Abhaengige_Regressionsvariable='Fahrten',\n",
    "                        DatenQuelle=DatenQuelle):\n",
    "    \n",
    "    Daten_LR_Modell = DatenQuelle.copy()\n",
    "    \n",
    "    Daten_Unabhaengige_Regressionsvariablen = Daten_LR_Modell[Liste_Unabhaengige_Regressionsvariablen]\n",
    "    Daten_Abhaengige_Regressionsvariable = Daten_LR_Modell[Abhaengige_Regressionsvariable]\n",
    "    \n",
    "    LR_Modell = LinearRegression(\n",
    "    ).fit(Daten_Unabhaengige_Regressionsvariablen, \n",
    "          Daten_Abhaengige_Regressionsvariable)\n",
    "    \n",
    "    Daten_LR_Modell['Trend'] = LR_Modell.predict(Daten_Unabhaengige_Regressionsvariablen)\n",
    "    \n",
    "    Daten_LR_Modell[Abhaengige_Regressionsvariable+'_trendbereinigt']\\\n",
    "    = Daten_LR_Modell[Abhaengige_Regressionsvariable] \\\n",
    "    - Daten_LR_Modell['Trend'] \\\n",
    "    + Daten_LR_Modell['Trend'].mean()\n",
    "    \n",
    "    for Unabhaengige_Ceteris_Paribus_Regressionsvariable \\\n",
    "    in Liste_Unabhaengige_Regressionsvariablen:\n",
    "        \n",
    "        Ceteris_Paribus_Regressionsdatensatz = pd.DataFrame(index=Daten_LR_Modell.index)\n",
    "        \n",
    "        for Unabhaengige_Regressionsvariable in Liste_Unabhaengige_Regressionsvariablen:\n",
    "            \n",
    "            if Unabhaengige_Regressionsvariable == Unabhaengige_Ceteris_Paribus_Regressionsvariable:\n",
    "                \n",
    "                Ceteris_Paribus_Regressionsdatensatz[Unabhaengige_Ceteris_Paribus_Regressionsvariable] \\\n",
    "                = DatenQuelle[Unabhaengige_Ceteris_Paribus_Regressionsvariable]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                Ceteris_Paribus_Regressionsdatensatz[Unabhaengige_Regressionsvariable] \\\n",
    "                = DatenQuelle[Unabhaengige_Regressionsvariable].mean()\n",
    "                \n",
    "        Daten_LR_Modell['Trend_' + Abhaengige_Regressionsvariable \\\n",
    "                        + '_iAv_'+ Unabhaengige_Ceteris_Paribus_Regressionsvariable] \\\n",
    "        = LR_Modell.predict(Ceteris_Paribus_Regressionsdatensatz)\n",
    "        \n",
    "        Daten_LR_Modell['Trend_' + Abhaengige_Regressionsvariable + '_trendbereinigt'\\\n",
    "                        + '_iAv_'+ Unabhaengige_Ceteris_Paribus_Regressionsvariable] \\\n",
    "        = Daten_LR_Modell['Trend_' + Abhaengige_Regressionsvariable \\\n",
    "                        + '_iAv_'+ Unabhaengige_Ceteris_Paribus_Regressionsvariable].mean()\n",
    "        \n",
    "    \n",
    "    return LR_Modell, Daten_LR_Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ein einfaches lineares Modell - Abhängigkeit der Fahrten von der Nummer des Tages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Liste_Unabhaengige_Regressionsvariablen = [\n",
    "    'Tag',\n",
    "]\n",
    "\n",
    "LR_Modell, Daten_LR_Modell = LR_Modell_und_Daten(\n",
    "    Liste_Unabhaengige_Regressionsvariablen=Liste_Unabhaengige_Regressionsvariablen,\n",
    "    Abhaengige_Regressionsvariable='Fahrten',\n",
    "    DatenQuelle=DatenQuelle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Daten_LR_Modell.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grafik_Uebersicht(Abhaengige_Variable='Fahrten', \n",
    "                  DatenQuelle=Daten_LR_Modell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Grafik_Uebersicht(Abhaengige_Variable='Fahrten_trendbereinigt', \n",
    "                  DatenQuelle=Daten_LR_Modell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Statistik(Liste_Unabhaengige_Regressionsvariablen=Liste_Unabhaengige_Regressionsvariablen,\n",
    "              Abhaengige_Regressionsvariable='Fahrten', \n",
    "              Daten_LR_Modell=Daten_LR_Modell, \n",
    "              LR_Modell=LR_Modell):\n",
    "    \n",
    "    Steigung = LR_Modell.coef_\n",
    "    \n",
    "    y = Daten_LR_Modell[Abhaengige_Regressionsvariable]\n",
    "    y_trend = Daten_LR_Modell['Trend']\n",
    "    X = Daten_LR_Modell[Liste_Unabhaengige_Regressionsvariablen]\n",
    "    \n",
    "    var_y = np.sum((y - y_trend) ** 2) / len(y)\n",
    "    X2 = np.hstack([X, np.ones((X.shape[0], 1))])\n",
    "    C = var_y * np.linalg.inv(np.dot(X2.T, X2))\n",
    "    var = C.diagonal()\n",
    "    \n",
    "    Fehler = np.sqrt(var[:])\n",
    "    \n",
    "    for Zaehler, Unabhaengige_Regressionsvariable \\\n",
    "    in enumerate(Liste_Unabhaengige_Regressionsvariablen):\n",
    "        \n",
    "        print('{0:.2f} +/- {1:.2f}'.format(Steigung[Zaehler], Fehler[Zaehler]), \n",
    "              Abhaengige_Regressionsvariable, \n",
    "              'je Einheit', \n",
    "              Unabhaengige_Regressionsvariable)\n",
    "              \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Statistik(Liste_Unabhaengige_Regressionsvariablen=Liste_Unabhaengige_Regressionsvariablen, \n",
    "          Abhaengige_Regressionsvariable='Fahrten', \n",
    "          Daten_LR_Modell=Daten_LR_Modell, \n",
    "          LR_Modell=LR_Modell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Lineare_Regressionsanalyse(\n",
    "    Liste_Unabhaengige_Regressionsvariablen=Liste_Unabhaengige_Regressionsvariablen,\n",
    "    Abhaengige_Regressionsvariable='Fahrten',\n",
    "    DatenQuelle=DatenQuelle):\n",
    "    \n",
    "    LR_Modell, Daten_LR_Modell = LR_Modell_und_Daten(\n",
    "        Liste_Unabhaengige_Regressionsvariablen=Liste_Unabhaengige_Regressionsvariablen,\n",
    "        Abhaengige_Regressionsvariable=Abhaengige_Regressionsvariable,\n",
    "        DatenQuelle=DatenQuelle)\n",
    "    \n",
    "    Grafik_Uebersicht_normal = \\\n",
    "    Grafik_Uebersicht(Abhaengige_Variable=Abhaengige_Regressionsvariable, \n",
    "                      DatenQuelle=Daten_LR_Modell)\n",
    "    \n",
    "    Grafik_Uebersicht_trendbereinigt = \\\n",
    "    Grafik_Uebersicht(Abhaengige_Variable=Abhaengige_Regressionsvariable + '_trendbereinigt', \n",
    "                      DatenQuelle=Daten_LR_Modell)\n",
    "    \n",
    "    Statistik(Liste_Unabhaengige_Regressionsvariablen=Liste_Unabhaengige_Regressionsvariablen,\n",
    "              Abhaengige_Regressionsvariable=Abhaengige_Regressionsvariable, \n",
    "              Daten_LR_Modell=Daten_LR_Modell, LR_Modell=LR_Modell)\n",
    "    \n",
    "    return Grafik_Uebersicht_normal & Grafik_Uebersicht_trendbereinigt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Lineare_Regressionsanalyse(['Tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Do-It-Yourself: Abhängigkeit der Fahrten von der Temperatur*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Lineare_Regressionsanalyse(['Temperatur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ein multi-lineares Modell - Abhängigkeit der Fahrten von Tageslänge und ist_Werktag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Lineare_Regressionsanalyse(['Tageslaenge', 'ist_Werktag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Do-It-Yourself: Abhängigkeit der Fahrten von Temperatur und Niederschlag*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das vollständige multi-lineare Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Lineare_Regressionsanalyse(['Tageslaenge', 'ist_Werktag', 'Temperatur', 'Niederschlag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Lineare_Regressionsanalyse(['Tageslaenge', 'ist_Werktag', 'Temperatur', 'Niederschlag', 'Tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergebnisse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
